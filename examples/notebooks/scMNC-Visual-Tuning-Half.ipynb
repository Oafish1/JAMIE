{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54a4980-d3b7-4664-9035-4abcb92b1ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342bee2d-d6d8-49aa-98ba-79a38ade4175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 01:48:56.817676: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-30 01:48:56.927289: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-30 01:48:56.932911: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-30 01:48:56.932924: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-30 01:48:56.967054: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-30 01:48:57.385620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-30 01:48:57.385691: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-30 01:48:57.385696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thema/miniconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from jamie import JAMIE\n",
    "from jamie.evaluation import *\n",
    "from jamie.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mmd_wrapper import mmd_combine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f7f25e-92e9-452e-8f48-5ac13b4e6ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "model_folder = './saved_models/'\n",
    "image_folder = './output_figures/tuning-half/'\n",
    "output_folder = './output_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6206e91-f09d-4d3b-81b1-461ea9c57df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'scMNC-Visual'\n",
    "dataset_color = 'magenta'\n",
    "modality_names = ['Gene Expression', 'Electrophysiology']\n",
    "data_folder = '../data/scMNC/mouse_visual_cortex/data/'\n",
    "data1 = pd.read_csv(data_folder + \"geneExp_filtered.csv\")\n",
    "data2 = pd.read_csv(data_folder + \"efeature_filtered.csv\")\n",
    "sample_names1 = data1.columns[1:]\n",
    "sample_names2 = np.array(data2)[:, 0]\n",
    "feature_names1 = data1.iloc[:,0]\n",
    "feature_names2 = data2.columns[3:]\n",
    "assert (sample_names1 == sample_names2).all()\n",
    "data1 = np.transpose(np.array(data1)[:, 1:])\n",
    "data2 = np.array(data2)[:, 3:]\n",
    "meta = pd.read_csv(data_folder + \"20200711_patchseq_metadata_mouse.csv\")\n",
    "meta_names = np.array(meta.columns)\n",
    "meta_sid = np.argwhere(meta_names == 'transcriptomics_sample_id')[0][0]\n",
    "meta_ttype = np.argwhere(meta_names == 't_type')[0][0]\n",
    "meta = np.array(meta)\n",
    "meta_idx = [np.argwhere(meta[:, meta_sid] == sample_names1[i])[0][0] for i in range(sample_names1.shape[0])]\n",
    "type1 = type2 = np.array([x.split(' ')[0] for x in meta[meta_idx, meta_ttype]])\n",
    "\n",
    "# Sampling\n",
    "# split = 1000 # data1.shape[0]\n",
    "# data_col_idx = np.random.choice(range(data1.shape[0]), split, replace=False)\n",
    "# data1, data2, type1, type2 = (x[data_col_idx] for x in (data1, data2, type1, type2))\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [np.array(feature_names1), np.array(feature_names2)]\n",
    "feature_dict = {}\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996d8fba-95bf-4e65-9269-da932ebdecb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e976c6dc-38f0-4ab0-b132-faf529ed7626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduced_dim = 32\n",
    "kwargs = {\n",
    "    'output_dim': reduced_dim,\n",
    "    'epoch_DNN': 10000,\n",
    "    'min_epochs': 2500,\n",
    "    'log_DNN': 500,\n",
    "    'use_early_stop': True,\n",
    "    'batch_size': 512,\n",
    "    'pca_dim': 2*[512],\n",
    "    'dist_method': 'euclidean',\n",
    "    'loss_weights': [1,1,1,1],\n",
    "    'dropout': 0,\n",
    "}\n",
    "kwargs_imp = {k: kwargs[k] for k in kwargs if k != 'dropout'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495eef51-49cd-4fc6-80a7-e77545e5ba56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "integrated_data = []\n",
    "integrated_names = []\n",
    "colors = []\n",
    "shapes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77e98ba-cbba-4ff0-8c76-3a338c9270da",
   "metadata": {},
   "source": [
    "# JAMIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e7a914-1ca1-4151-bc0b-6047fe7d966c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model './saved_models/jm---scMNC-Visual---3654-1302---3654-39---dropout-0.h5'\n"
     ]
    }
   ],
   "source": [
    "# Integration\n",
    "size_str, hash_str = hash_kwargs(kwargs, dataset_name, dataset)\n",
    "prefix = model_folder + 'jm---'\n",
    "model_str = prefix + hash_str + '.h5'\n",
    "match_str = prefix + size_str + '.npy'\n",
    "\n",
    "# Instantiate\n",
    "mr = list(np.load(match_str, allow_pickle=True)) if os.path.exists(match_str) else None\n",
    "jm = JAMIE(**kwargs, match_result=mr, debug=True)\n",
    "\n",
    "# Train\n",
    "if os.path.exists(model_str):\n",
    "    jm.load_model(model_str)\n",
    "    print(f'Loaded model \\'{model_str}\\'')\n",
    "else:\n",
    "    jm_data = jm.fit_transform(dataset=dataset, P=half_priors)\n",
    "    jm.save_model(model_str)\n",
    "    np.save(match_str, jm.match_result, allow_pickle=True)\n",
    "jm_data = jm.transform(dataset=dataset)\n",
    "integrated_data.append(jm_data)\n",
    "integrated_names.append('JAMIE')\n",
    "colors.append('blue')\n",
    "shapes.append('8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "badd253e-16e0-444c-bed5-22b7bc8283cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\\gamma=0$: [1, 1, 1, 0]\n",
      "Loaded model './saved_models/jm_50---scMNC-Visual---3654-1302---3654-39---dropout-0--loss_weights-(1-1-1-0).h5'\n",
      "\n",
      "$\\beta=0$: [1, 1, 0, 1]\n",
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (3654, 1302)\n",
      "Dataset 1: (3654, 39)\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:422: UserWarning: PCA dim must be lower than 39, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 - KL: 0.0018  Rec: 0.2938  CosSim: 0.0000  F: 0.0237\n",
      "Epoch: 200 - KL: 0.0034  Rec: 0.2193  CosSim: 0.0000  F: 0.0189\n",
      "Epoch: 300 - KL: 0.0048  Rec: 0.1784  CosSim: 0.0000  F: 0.0148\n",
      "Epoch: 400 - KL: 0.0079  Rec: 0.1621  CosSim: 0.0000  F: 0.0130\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# result = run_jamie({k: kwargs[k] if k != 'loss_weights' else lw for k in kwargs}, half_priors, 'jm_50---')\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_jamie\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss_weights\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m integrated_data\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     32\u001b[0m integrated_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJAMIE (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [9], line 17\u001b[0m, in \u001b[0;36mrun_jamie\u001b[0;34m(kwargs, dataset, idx, prior, hashName)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoaded model \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     jm_data \u001b[38;5;241m=\u001b[39m \u001b[43mjm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     jm\u001b[38;5;241m.\u001b[39msave_model(model_str)\n\u001b[1;32m     19\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(match_str, jm\u001b[38;5;241m.\u001b[39mmatch_result, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:200\u001b[0m, in \u001b[0;36mJAMIE.fit_transform\u001b[0;34m(self, dataset, P)\u001b[0m\n\u001b[1;32m    198\u001b[0m             k \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    199\u001b[0m         match_matrix[i][j] \u001b[38;5;241m=\u001b[39m mat\n\u001b[0;32m--> 200\u001b[0m     integrated_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject_jamie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m time\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMapping\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m33\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:593\u001b[0m, in \u001b[0;36mJAMIE.project_jamie\u001b[0;34m(self, W)\u001b[0m\n\u001b[1;32m    586\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPF_Ratio \u001b[38;5;241m*\u001b[39m P \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPF_Ratio) \u001b[38;5;241m*\u001b[39m F\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# F_thresh = torch.zeros_like(F)\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m# F_thresh[F >= torch.max(F, dim=1, keepdim=True).values] = 1\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# F_thresh = F_thresh / torch.norm(F_thresh, dim=1, keepdim=True)\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# corr = self.PF_Ratio * P + (1-self.PF_Ratio) * F_thresh\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# Run model\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m embedded, combined, reconstructed, mus, logvars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m timer\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# Loss bookkeeping\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/c/Users/nck/repos/nmacom/jamie/model.py:273\u001b[0m, in \u001b[0;36medModelVar.forward\u001b[0;34m(self, corr, *X)\u001b[0m\n\u001b[1;32m    271\u001b[0m zs, mus, logvars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefactor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(X))\n\u001b[1;32m    272\u001b[0m combined \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine(zs, corr)\n\u001b[0;32m--> 273\u001b[0m X_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m zs, combined, X_hat, mus, logvars\n",
      "File \u001b[0;32m/mnt/c/Users/nck/repos/nmacom/jamie/model.py:262\u001b[0m, in \u001b[0;36medModelVar.decode\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoders[i](X[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_modalities)]\n",
      "File \u001b[0;32m/mnt/c/Users/nck/repos/nmacom/jamie/model.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_modalities)]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:1847\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight):\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(linear, (\u001b[38;5;28minput\u001b[39m, weight), \u001b[38;5;28minput\u001b[39m, weight, bias\u001b[38;5;241m=\u001b[39mbias)\n\u001b[0;32m-> 1847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_jamie(kwargs, dataset, idx=None, prior=half_priors, hashName='jm_50---'):\n",
    "    size_str, hash_str = hash_kwargs(kwargs, dataset_name, dataset)\n",
    "    prefix = model_folder + hashName\n",
    "    model_str = prefix + hash_str + '.h5'\n",
    "    match_str = prefix + size_str + '.npy'\n",
    "\n",
    "    # Instantiate\n",
    "    mr = list(np.load(match_str, allow_pickle=True)) if os.path.exists(match_str) else None\n",
    "    jm = JAMIE(**kwargs, match_result=mr, debug=True)\n",
    "\n",
    "    # Train\n",
    "    if os.path.exists(model_str):\n",
    "        jm.load_model(model_str)\n",
    "        print(f'Loaded model \\'{model_str}\\'')\n",
    "    else:\n",
    "        jm_data = jm.fit_transform(dataset=dataset if idx is None else [d[idx] for d in dataset], P=prior)\n",
    "        jm.save_model(model_str)\n",
    "        np.save(match_str, jm.match_result, allow_pickle=True)\n",
    "    jm_data = jm.transform(dataset=dataset)\n",
    "    \n",
    "    return jm, jm_data\n",
    "\n",
    "for name, lw, cl in zip(\n",
    "    ('$\\\\gamma=0$', '$\\\\beta=0$', '$\\\\alpha=0$', '$\\\\kappa=0$'),\n",
    "    ([1,1,1,0],[1,1,0,1],[1,0,1,1],[0,1,1,1]),\n",
    "    ('pink', 'orange', 'green', 'red'),):\n",
    "    print(f'{name}: {lw}')\n",
    "    # result = run_jamie({k: kwargs[k] if k != 'loss_weights' else lw for k in kwargs}, half_priors, 'jm_50---')\n",
    "    result = run_jamie({k: kwargs[k] if k != 'loss_weights' else lw for k in kwargs}, dataset)\n",
    "    integrated_data.append(result[1])\n",
    "    integrated_names.append(f'JAMIE ({name})')\n",
    "    colors.append(cl)\n",
    "    shapes.append('o')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af75499-70fd-46fa-8275-3eba35edbeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = run_jamie({k: kwargs[k] if k != 'pca_dim' else 2*[128] for k in kwargs}, dataset)\n",
    "integrated_data.append(result[1])\n",
    "integrated_names.append('JAMIE (pca$=128$)')\n",
    "colors.append('yellow')\n",
    "shapes.append('s')\n",
    "\n",
    "result = run_jamie({k: kwargs[k] if k != 'pca_dim' else 2*[32] for k in kwargs}, dataset)\n",
    "integrated_data.append(result[1])\n",
    "integrated_names.append('JAMIE (pca$=32$)')\n",
    "colors.append('purple')\n",
    "shapes.append('s')\n",
    "\n",
    "result = run_jamie({k: kwargs[k] if k != 'output_dim' else 16 for k in kwargs}, dataset)\n",
    "integrated_data.append(result[1])\n",
    "integrated_names.append('JAMIE ($g=16$)')\n",
    "colors.append('teal')\n",
    "shapes.append('*')\n",
    "\n",
    "result = run_jamie({k: kwargs[k] if k != 'output_dim' else 8 for k in kwargs}, dataset)\n",
    "integrated_data.append(result[1])\n",
    "integrated_names.append('JAMIE ($g=8$)')\n",
    "colors.append('lime')\n",
    "shapes.append('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b2bd1-3c28-4c8a-a4ee-e082327e245b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputation\n",
    "size_str, hash_str = hash_kwargs(kwargs_imp, dataset_name, dataset)\n",
    "prefix = model_folder + 'jm_im_50---'\n",
    "model_str = prefix + hash_str + '.h5'\n",
    "match_str = prefix + size_str + '.npy'\n",
    "\n",
    "# Instantiate\n",
    "mr = list(np.load(match_str, allow_pickle=True)) if os.path.exists(match_str) else None\n",
    "jm_im = JAMIE(**kwargs_imp, match_result=mr, debug=True)\n",
    "\n",
    "# Train\n",
    "if os.path.exists(model_str):\n",
    "    jm_im.load_model(model_str)\n",
    "    print(f'Loaded model \\'{model_str}\\'')\n",
    "else:\n",
    "    jm_im.fit_transform(dataset=[d[train_idx] for d in dataset], , P=half_priors)\n",
    "    jm_im.save_model(model_str)\n",
    "    np.save(match_str, jm_im.match_result, allow_pickle=True)\n",
    "jm_imputed = [jm_im.modal_predict(dataset[i], i) for i in range(1, -1, -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d99220-338d-4c07-8d00-3cea04dfb9db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparison Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e0410-1566-40bb-a4af-a239ce2d534f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imputation\n",
    "if False:\n",
    "    imputation_name = 'Babel'\n",
    "else:\n",
    "    imputation_name = 'KNN'\n",
    "    nn_imputed = [predict_knn(torch.tensor(dataset[i][train_idx]).float(), torch.tensor(dataset[(i+1)%2][train_idx]).float(), torch.tensor(dataset[i]).float()) for i in range(1, -1, -1)]\n",
    "imputed_data_full = [jm_imputed, nn_imputed][::-1]\n",
    "imputed_data = [[d[test_idx] for d in ds] for ds in imputed_data_full]\n",
    "imputed_names = ['JAMIE (.5)', imputation_name][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae5533-a8ae-4d74-aa86-4d17c4df66d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa19bcc-b80a-4b83-9c30-5e650c7b08f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "style='white'\n",
    "sns.set(style=style)\n",
    "plt.rcParams.update({'font.weight': 'normal',\n",
    "                     'font.size': 18,\n",
    "                     'axes.titlesize': 'large',\n",
    "                     'axes.labelsize': 'large',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53abb3d-ec8f-4ea4-8265-f50f6febe527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "algorithm_elements = [Line2D([0], [0], marker='s', color='w', markerfacecolor=c, label=n, markersize=10) for n, c in zip(integrated_names, colors)]\n",
    "label_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor=plt.rcParams['axes.prop_cycle'].by_key()['color'][i], label=l, markersize=10) for i, l in enumerate(np.unique(labels))]\n",
    "\n",
    "# https://stackoverflow.com/a/47749903\n",
    "fig, ax = plt.subplots()\n",
    "legend = ax.legend(handles=label_elements, loc='center', frameon=False, ncol=min(len(label_elements), 4))\n",
    "legend.figure.canvas.draw()\n",
    "bbox = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.axis('off')\n",
    "plt.savefig(image_folder + dataset_name + '-LabelLegend.png', bbox_inches=bbox, dpi=300)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "legend = ax.legend(handles=algorithm_elements, loc='center', frameon=False)\n",
    "legend.figure.canvas.draw()\n",
    "bbox = legend.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "plt.axis('off')\n",
    "plt.savefig(image_folder + dataset_name + '-AlgorithmLegend.png', bbox_inches=bbox, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cd65b-1244-4041-9131-bcf0e9438a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display( Image(filename=image_folder + dataset_name + '-LabelLegend.png', width=400) )\n",
    "display( Image(filename=image_folder + dataset_name + '-AlgorithmLegend.png', width=100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4723da3-6312-4ebf-af0c-99ea531a9fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "plot_regular(dataset, labels, modality_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig(image_folder + dataset_name + '-Data.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400954e4-0a78-4238-a0ce-e420e5716b2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for d, n in zip(integrated_data, integrated_names):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plot_integrated(d, labels, [f'{n} - ' + mn for mn in modality_names])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_folder + dataset_name + f'-{n}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47589137-0334-4907-955e-0e707393c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_idx = [0, 1, 2, 3, 4]\n",
    "pca_idx = [0, 5, 6]\n",
    "dim_idx = [0, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb580074-eada-41ae-8af1-2ff87dbf1e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "idx = weight_idx\n",
    "plot_accuracy_graph([integrated_data[i] for i in idx], labels, [integrated_names[i] for i in idx], colors=[colors[i] for i in idx], shapes=[shapes[i] for i in idx])\n",
    "plt.savefig(image_folder + dataset_name + '-AccWeight.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8e784-02d1-4e09-a614-8bed715a4a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "idx = pca_idx\n",
    "plot_accuracy_graph([integrated_data[i] for i in idx], labels, [integrated_names[i] for i in idx], colors=[colors[i] for i in idx], shapes=[shapes[i] for i in idx])\n",
    "plt.savefig(image_folder + dataset_name + '-AccPCA.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a2953-6a8d-4e3a-b715-3b3dd24b2332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "idx = dim_idx\n",
    "plot_accuracy_graph([integrated_data[i] for i in idx], labels, [integrated_names[i] for i in idx], colors=[colors[i] for i in idx], shapes=[shapes[i] for i in idx])\n",
    "plt.savefig(image_folder + dataset_name + '-AccDim.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ac27a-86ef-4f48-8682-d0ea87e8e40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 5))\n",
    "# plot_silhouette([[d[0]] for d in integrated_data], [labels[0]], integrated_names, modality_names[:1], colors=colors)\n",
    "# sns.despine()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(image_folder + dataset_name + '-Sil.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1deee8-2f30-4a5f-99a9-2337433d9509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_auroc_correlation(imputed_data, [data1[test_idx], data2[test_idx]], modality_names, index=0, names=imputed_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig(image_folder + dataset_name + '-Imp1.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd898d6e-e302-4f3d-acea-e15caf0ba04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_auroc_correlation(imputed_data, [data1[test_idx], data2[test_idx]], modality_names, index=1, names=imputed_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig(image_folder + dataset_name + '-Imp2.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e37010-7ce5-40a2-96b5-80a04e698f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_distribution_alone([dataset[0][test_idx], jm_imputed[0][test_idx]], 2*[labels[0][test_idx]], title=modality_names[0], fnames=2*[features[0]], feature_dict=feature_dict)\n",
    "sns.despine()\n",
    "plt.savefig(image_folder + dataset_name + '-Dist1.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e610d561-8876-457a-b160-6567211453fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_distribution_alone([dataset[1], jm_imputed[1]], 2*[labels[1]], title=modality_names[1], fnames=2*[features[1]], feature_dict=feature_dict, remove_outliers=False)\n",
    "sns.despine()\n",
    "plt.savefig(image_folder + dataset_name + '-Dist2.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b6fea-6c01-419c-847c-ffb276a14b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plot_distribution_similarity([dataset[0][test_idx], jm_imputed[0][test_idx]], 2*[labels[0][test_idx]], title=modality_names[0], fnames=2*[features[0]])\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(image_folder + dataset_name + '-Sim1.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283c562f-0ae9-4de1-af2c-a178e095a8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plot_distribution_similarity([dataset[1][test_idx], jm_imputed[1][test_idx]], 2*[labels[1][test_idx]], title=modality_names[1], fnames=2*[features[1]])\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(image_folder + dataset_name + '-Sim2.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "068ab10e55f04004ac32deed9c92f560": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e2331f54a2284f3784807f3bfabfaeaa",
       "placeholder": "​",
       "style": "IPY_MODEL_94e3928a288e48588e1b088a43685788",
       "tabbable": null,
       "tooltip": null,
       "value": " 500/500 [00:37&lt;00:00, 13.65it/s]"
      }
     },
     "091c6290c2cc49fc816a9cc517462bd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aa3ab1fce6b64102836cda81a8b54dbb",
        "IPY_MODEL_d7df1df009af4c90b415b37a80ec7bba",
        "IPY_MODEL_068ab10e55f04004ac32deed9c92f560"
       ],
       "layout": "IPY_MODEL_c8c53bdd3745489ca0198681fd828619",
       "tabbable": null,
       "tooltip": null
      }
     },
     "519a993ec5224a629aff1440cfce7e8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "687dd8e01a514c6284a6cae8a4c4f8b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8209866b5fb044f7aa07f549014db263": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "94e3928a288e48588e1b088a43685788": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aa3ab1fce6b64102836cda81a8b54dbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_687dd8e01a514c6284a6cae8a4c4f8b4",
       "placeholder": "​",
       "style": "IPY_MODEL_8209866b5fb044f7aa07f549014db263",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "c8c53bdd3745489ca0198681fd828619": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccd2ad01b347423eb536cb6181b00f60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d7df1df009af4c90b415b37a80ec7bba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_519a993ec5224a629aff1440cfce7e8e",
       "max": 500,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ccd2ad01b347423eb536cb6181b00f60",
       "tabbable": null,
       "tooltip": null,
       "value": 500
      }
     },
     "e2331f54a2284f3784807f3bfabfaeaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
