{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f57ea00-b9ec-4cfe-a819-4e16d365d6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92eb915-cb7c-4663-a778-c7d28524c587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 23:39:14.395774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-12 23:39:14.475566: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-12 23:39:14.478720: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-12 23:39:14.478729: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-12 23:39:14.495062: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-12 23:39:14.861291: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-12 23:39:14.861357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-12 23:39:14.861362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thema/miniconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from jamie import JAMIE\n",
    "from jamie.evaluation import *\n",
    "from jamie.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "from mmd_wrapper import mmd_combine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8901cbfb-73c9-4099-8865-9f4efa8f1262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1106a98-0665-49fe-b72e-cf75c40aef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'output_dim': 32,\n",
    "    'epoch_DNN': 10000,\n",
    "    'min_epochs': 2500,\n",
    "    'log_DNN': 500,\n",
    "    'use_early_stop': True,\n",
    "    'batch_size': 512,\n",
    "    'pca_dim': 2*[512],\n",
    "    'dist_method': 'euclidean',\n",
    "    'loss_weights': [1,1,1,1],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009ecf8-9bba-4ef8-9900-fefdda586267",
   "metadata": {},
   "source": [
    "# MMD-MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6206e91-f09d-4d3b-81b1-461ea9c57df2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1272/4179390009.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  type1 = type1.astype(np.int)\n",
      "/tmp/ipykernel_1272/4179390009.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  type2 = type2.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'MMD-MA'\n",
    "dataset_color = 'lime'\n",
    "modality_names = ['Modality 1', 'Modality 2']\n",
    "data_folder = '../data/UnionCom/MMD/'\n",
    "data1 = np.loadtxt(data_folder + \"s1_mapped1.txt\")\n",
    "data2 = np.loadtxt(data_folder + \"s1_mapped2.txt\")\n",
    "type1 = np.loadtxt(data_folder + \"s1_type1.txt\")\n",
    "type2 = np.loadtxt(data_folder + \"s1_type2.txt\")\n",
    "type1 = type1.astype(np.int)\n",
    "type2 = type2.astype(np.int)\n",
    "type1 = np.array([f'Cell Type {i}' for i in type1])\n",
    "type2 = np.array([f'Cell Type {i}' for i in type2])\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [None, None]\n",
    "feature_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd13b4ae-ce65-4838-a18a-29f61bc9d0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b6aa83-78c0-4450-a8aa-19676e9567d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (300, 2000)\n",
      "Dataset 1: (300, 1000)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:11.7152 alpha:0.1578\n",
      "epoch:[1000/2000] err:10.2456 alpha:0.3746\n",
      "epoch:[1500/2000] err:10.1076 alpha:0.4565\n",
      "epoch:[2000/2000] err:10.0670 alpha:0.4759\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:427: UserWarning: PCA dim must be lower than 300, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:427: UserWarning: PCA dim must be lower than 300, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 - KL: 0.0016  Rec: 0.3937  CosSim: 0.1242  F: 0.0076\n",
      "Epoch: 200 - KL: 0.0034  Rec: 0.3471  CosSim: 0.0354  F: 0.0052\n",
      "Epoch: 300 - KL: 0.0075  Rec: 0.3299  CosSim: 0.0275  F: 0.0049\n",
      "Epoch: 400 - KL: 0.0104  Rec: 0.3238  CosSim: 0.0215  F: 0.0036\n",
      "Epoch: 500 - KL: 0.0132  Rec: 0.3179  CosSim: 0.0218  F: 0.0042\n",
      "epoch:[500/10000]: loss:0.357045\n",
      "Epoch: 600 - KL: 0.0167  Rec: 0.3220  CosSim: 0.0197  F: 0.0039\n",
      "Epoch: 700 - KL: 0.0255  Rec: 0.3097  CosSim: 0.0219  F: 0.0041\n",
      "Epoch: 800 - KL: 0.0416  Rec: 0.3024  CosSim: 0.0233  F: 0.0036\n",
      "Epoch: 900 - KL: 0.0559  Rec: 0.3068  CosSim: 0.0232  F: 0.0038\n",
      "Epoch: 1000 - KL: 0.0682  Rec: 0.3027  CosSim: 0.0244  F: 0.0036\n",
      "epoch:[1000/10000]: loss:0.399021\n",
      "Epoch: 1100 - KL: 0.0855  Rec: 0.2954  CosSim: 0.0286  F: 0.0034\n",
      "Epoch: 1200 - KL: 0.0886  Rec: 0.2994  CosSim: 0.0341  F: 0.0040\n",
      "Epoch: 1300 - KL: 0.1167  Rec: 0.2974  CosSim: 0.0370  F: 0.0034\n",
      "Epoch: 1400 - KL: 0.1138  Rec: 0.2984  CosSim: 0.0402  F: 0.0039\n",
      "Epoch: 1500 - KL: 0.1841  Rec: 0.2992  CosSim: 0.0418  F: 0.0037\n",
      "epoch:[1500/10000]: loss:0.528862\n",
      "Epoch: 1600 - KL: 0.1651  Rec: 0.2928  CosSim: 0.0404  F: 0.0038\n",
      "Epoch: 1700 - KL: 0.1588  Rec: 0.2863  CosSim: 0.0457  F: 0.0038\n",
      "Epoch: 1800 - KL: 0.1259  Rec: 0.2947  CosSim: 0.0464  F: 0.0037\n",
      "Epoch: 1900 - KL: 0.1613  Rec: 0.3003  CosSim: 0.0468  F: 0.0035\n",
      "Epoch: 2000 - KL: 0.1939  Rec: 0.2915  CosSim: 0.0428  F: 0.0036\n",
      "epoch:[2000/10000]: loss:0.531770\n",
      "Epoch: 2100 - KL: 0.1596  Rec: 0.2975  CosSim: 0.0456  F: 0.0035\n",
      "Epoch: 2200 - KL: 0.1644  Rec: 0.2958  CosSim: 0.0446  F: 0.0029\n",
      "Epoch: 2300 - KL: 0.1893  Rec: 0.2895  CosSim: 0.0430  F: 0.0030\n",
      "Epoch: 2400 - KL: 0.1928  Rec: 0.2863  CosSim: 0.0433  F: 0.0030\n",
      "Epoch: 2500 - KL: 0.1792  Rec: 0.2870  CosSim: 0.0446  F: 0.0033\n",
      "epoch:[2500/10000]: loss:0.514105\n",
      "Epoch: 2600 - KL: 0.1738  Rec: 0.2923  CosSim: 0.0450  F: 0.0031\n",
      "Epoch: 2700 - KL: 0.1640  Rec: 0.2969  CosSim: 0.0425  F: 0.0030\n",
      "Epoch: 2800 - KL: 0.1825  Rec: 0.2915  CosSim: 0.0453  F: 0.0032\n",
      "Epoch: 2900 - KL: 0.1885  Rec: 0.2930  CosSim: 0.0422  F: 0.0030\n",
      "Epoch: 3000 - KL: 0.1932  Rec: 0.2827  CosSim: 0.0423  F: 0.0029\n",
      "epoch:[3000/10000]: loss:0.521067\n",
      "Epoch: 3100 - KL: 0.1965  Rec: 0.2902  CosSim: 0.0387  F: 0.0027\n",
      "Epoch: 3200 - KL: 0.1713  Rec: 0.2900  CosSim: 0.0452  F: 0.0028\n",
      "Epoch: 3300 - KL: 0.1475  Rec: 0.2888  CosSim: 0.0438  F: 0.0028\n",
      "Epoch: 3400 - KL: 0.1971  Rec: 0.2878  CosSim: 0.0418  F: 0.0028\n",
      "Epoch: 3500 - KL: 0.1702  Rec: 0.2871  CosSim: 0.0446  F: 0.0027\n",
      "epoch:[3500/10000]: loss:0.504586\n",
      "Epoch: 3600 - KL: 0.1906  Rec: 0.2909  CosSim: 0.0400  F: 0.0028\n",
      "Epoch: 3700 - KL: 0.1834  Rec: 0.2868  CosSim: 0.0411  F: 0.0027\n",
      "Epoch: 3800 - KL: 0.2037  Rec: 0.2899  CosSim: 0.0405  F: 0.0028\n",
      "Finished Mapping!\n",
      "Setup: 0.14060400100424886\n",
      "Get subset samples: 0.0010199886796191018\n",
      "Run model: 0.007998039413541703\n",
      "KL Loss: 0.00027012117219040095\n",
      "Reconstruction Loss: 0.00017975526288704888\n",
      "Difference calculation: 0.0006123806310611283\n",
      "Cosine Loss: 0.00012106468728110555\n",
      "F Loss: 7.058511270964418e-05\n",
      "Step: 0.01775695858341341\n",
      "Output: 0.006130232010036707\n",
      "Total: 0.1747631265569891\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 0.13119221899250988\n",
      "Distance Memory: Stored 1772598 - Peak 2762820\n",
      "Correspondence: 4.310733748003258\n",
      "Correspondence Memory: Stored 367028 - Peak 1441616\n",
      "Mapping: 107.06516846999875\n",
      "Mapping Memory: Stored 9381724 - Peak 18054245\n",
      "Total: 111.50709443699452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06e561-3e59-4e8d-8193-70679f01ded9",
   "metadata": {},
   "source": [
    "# Simulation 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ad8448-6b2e-4305-945c-fda8da7297ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'scMultiSim-1250'\n",
    "dataset_color = 'teal'\n",
    "modality_names = ['Modality 1', 'Modality 2']\n",
    "data_folder = '../data/scMultiSim/new/'\n",
    "data1 = np.loadtxt(data_folder + \"scMultiSim_RNA_counts_1250_genes.csv\", delimiter=\",\", skiprows=1)\n",
    "data2 = np.loadtxt(data_folder + \"scMultiSim_ATAC_seq_1250_genes_new.csv\", delimiter=\",\", skiprows=1)\n",
    "ct = pd.read_csv(data_folder + \"cell_meta_1250_genes.csv\").iloc[3, 1:].to_numpy().astype(int)\n",
    "type1 = type2 = np.array([f'Cell Type {i}' for i in ct])\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [None, None]\n",
    "feature_dict = {}\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd74c79d-fece-45fb-a79c-a3409bac767c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81100a48-7ed9-4db9-a4b3-c36a48291dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (500, 1250)\n",
      "Dataset 1: (500, 3750)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:13.0043 alpha:0.0774\n",
      "epoch:[1000/2000] err:16.3444 alpha:0.1053\n",
      "epoch:[1500/2000] err:18.7388 alpha:0.1709\n",
      "epoch:[2000/2000] err:21.0007 alpha:0.4030\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:427: UserWarning: PCA dim must be lower than 500, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:427: UserWarning: PCA dim must be lower than 500, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 - KL: 0.0025  Rec: 1.1084  CosSim: 0.0669  F: 0.0054\n",
      "Epoch: 200 - KL: 0.0040  Rec: 0.9321  CosSim: 0.0375  F: 0.0052\n",
      "Epoch: 300 - KL: 0.0064  Rec: 0.8628  CosSim: 0.0319  F: 0.0054\n",
      "Epoch: 400 - KL: 0.0090  Rec: 0.8166  CosSim: 0.0298  F: 0.0053\n",
      "Epoch: 500 - KL: 0.0143  Rec: 0.7929  CosSim: 0.0271  F: 0.0052\n",
      "epoch:[500/10000]: loss:0.839573\n",
      "Epoch: 600 - KL: 0.0170  Rec: 0.7661  CosSim: 0.0248  F: 0.0046\n",
      "Epoch: 700 - KL: 0.0279  Rec: 0.7453  CosSim: 0.0251  F: 0.0044\n",
      "Epoch: 800 - KL: 0.0437  Rec: 0.7315  CosSim: 0.0250  F: 0.0047\n",
      "Epoch: 900 - KL: 0.0384  Rec: 0.7200  CosSim: 0.0256  F: 0.0044\n",
      "Epoch: 1000 - KL: 0.0732  Rec: 0.7135  CosSim: 0.0264  F: 0.0044\n",
      "epoch:[1000/10000]: loss:0.817421\n",
      "Epoch: 1100 - KL: 0.0787  Rec: 0.7092  CosSim: 0.0291  F: 0.0044\n",
      "Epoch: 1200 - KL: 0.1102  Rec: 0.7003  CosSim: 0.0314  F: 0.0045\n",
      "Epoch: 1300 - KL: 0.1421  Rec: 0.6863  CosSim: 0.0354  F: 0.0047\n",
      "Epoch: 1400 - KL: 0.1302  Rec: 0.6853  CosSim: 0.0388  F: 0.0047\n",
      "Epoch: 1500 - KL: 0.1455  Rec: 0.6734  CosSim: 0.0400  F: 0.0047\n",
      "epoch:[1500/10000]: loss:0.863549\n",
      "Epoch: 1600 - KL: 0.1961  Rec: 0.6688  CosSim: 0.0444  F: 0.0047\n",
      "Epoch: 1700 - KL: 0.1771  Rec: 0.6750  CosSim: 0.0494  F: 0.0048\n",
      "Epoch: 1800 - KL: 0.1612  Rec: 0.6507  CosSim: 0.0463  F: 0.0045\n",
      "Epoch: 1900 - KL: 0.1838  Rec: 0.6540  CosSim: 0.0454  F: 0.0046\n",
      "Epoch: 2000 - KL: 0.2095  Rec: 0.6457  CosSim: 0.0475  F: 0.0047\n",
      "epoch:[2000/10000]: loss:0.907394\n",
      "Epoch: 2100 - KL: 0.2388  Rec: 0.6444  CosSim: 0.0478  F: 0.0046\n",
      "Epoch: 2200 - KL: 0.1784  Rec: 0.6310  CosSim: 0.0540  F: 0.0047\n",
      "Epoch: 2300 - KL: 0.2298  Rec: 0.6381  CosSim: 0.0473  F: 0.0047\n",
      "Epoch: 2400 - KL: 0.1804  Rec: 0.6246  CosSim: 0.0504  F: 0.0048\n",
      "Epoch: 2500 - KL: 0.1765  Rec: 0.6236  CosSim: 0.0493  F: 0.0045\n",
      "epoch:[2500/10000]: loss:0.853859\n",
      "Epoch: 2600 - KL: 0.1667  Rec: 0.6198  CosSim: 0.0487  F: 0.0043\n",
      "Epoch: 2700 - KL: 0.1749  Rec: 0.6075  CosSim: 0.0497  F: 0.0045\n",
      "Epoch: 2800 - KL: 0.1982  Rec: 0.6172  CosSim: 0.0457  F: 0.0042\n",
      "Epoch: 2900 - KL: 0.1627  Rec: 0.6151  CosSim: 0.0500  F: 0.0045\n",
      "Epoch: 3000 - KL: 0.1881  Rec: 0.6085  CosSim: 0.0480  F: 0.0045\n",
      "epoch:[3000/10000]: loss:0.849055\n",
      "Epoch: 3100 - KL: 0.1800  Rec: 0.5998  CosSim: 0.0487  F: 0.0042\n",
      "Epoch: 3200 - KL: 0.1891  Rec: 0.5943  CosSim: 0.0438  F: 0.0041\n",
      "Epoch: 3300 - KL: 0.1676  Rec: 0.5947  CosSim: 0.0465  F: 0.0043\n",
      "Epoch: 3400 - KL: 0.1797  Rec: 0.5919  CosSim: 0.0463  F: 0.0042\n",
      "Epoch: 3500 - KL: 0.1868  Rec: 0.5905  CosSim: 0.0471  F: 0.0041\n",
      "epoch:[3500/10000]: loss:0.828523\n",
      "Epoch: 3600 - KL: 0.1908  Rec: 0.5913  CosSim: 0.0465  F: 0.0042\n",
      "Epoch: 3700 - KL: 0.1736  Rec: 0.5919  CosSim: 0.0484  F: 0.0045\n",
      "Epoch: 3800 - KL: 0.1701  Rec: 0.5862  CosSim: 0.0467  F: 0.0042\n",
      "Epoch: 3900 - KL: 0.1756  Rec: 0.5738  CosSim: 0.0447  F: 0.0042\n",
      "Epoch: 4000 - KL: 0.1613  Rec: 0.5913  CosSim: 0.0472  F: 0.0042\n",
      "epoch:[4000/10000]: loss:0.804013\n",
      "Epoch: 4100 - KL: 0.1836  Rec: 0.5734  CosSim: 0.0423  F: 0.0041\n",
      "Epoch: 4200 - KL: 0.1730  Rec: 0.5769  CosSim: 0.0471  F: 0.0042\n",
      "Epoch: 4300 - KL: 0.2193  Rec: 0.5813  CosSim: 0.0442  F: 0.0040\n",
      "Epoch: 4400 - KL: 0.1723  Rec: 0.5679  CosSim: 0.0482  F: 0.0042\n",
      "Epoch: 4500 - KL: 0.1812  Rec: 0.5734  CosSim: 0.0440  F: 0.0038\n",
      "epoch:[4500/10000]: loss:0.802468\n",
      "Epoch: 4600 - KL: 0.1834  Rec: 0.5778  CosSim: 0.0447  F: 0.0041\n",
      "Epoch: 4700 - KL: 0.2028  Rec: 0.5589  CosSim: 0.0449  F: 0.0040\n",
      "Epoch: 4800 - KL: 0.1865  Rec: 0.5605  CosSim: 0.0437  F: 0.0039\n",
      "Epoch: 4900 - KL: 0.2111  Rec: 0.5511  CosSim: 0.0444  F: 0.0041\n",
      "Epoch: 5000 - KL: 0.1765  Rec: 0.5613  CosSim: 0.0424  F: 0.0039\n",
      "epoch:[5000/10000]: loss:0.784089\n",
      "Epoch: 5100 - KL: 0.1663  Rec: 0.5480  CosSim: 0.0460  F: 0.0039\n",
      "Epoch: 5200 - KL: 0.2056  Rec: 0.5474  CosSim: 0.0425  F: 0.0041\n",
      "Epoch: 5300 - KL: 0.2045  Rec: 0.5447  CosSim: 0.0411  F: 0.0038\n",
      "Epoch: 5400 - KL: 0.1824  Rec: 0.5486  CosSim: 0.0426  F: 0.0039\n",
      "Epoch: 5500 - KL: 0.1653  Rec: 0.5435  CosSim: 0.0434  F: 0.0039\n",
      "epoch:[5500/10000]: loss:0.756037\n",
      "Epoch: 5600 - KL: 0.1768  Rec: 0.5519  CosSim: 0.0429  F: 0.0036\n",
      "Epoch: 5700 - KL: 0.1990  Rec: 0.5435  CosSim: 0.0439  F: 0.0037\n",
      "Epoch: 5800 - KL: 0.1779  Rec: 0.5303  CosSim: 0.0418  F: 0.0041\n",
      "Epoch: 5900 - KL: 0.1944  Rec: 0.5425  CosSim: 0.0418  F: 0.0039\n",
      "Epoch: 6000 - KL: 0.1920  Rec: 0.5543  CosSim: 0.0415  F: 0.0034\n",
      "epoch:[6000/10000]: loss:0.791141\n",
      "Epoch: 6100 - KL: 0.1904  Rec: 0.5537  CosSim: 0.0431  F: 0.0036\n",
      "Epoch: 6200 - KL: 0.1635  Rec: 0.5295  CosSim: 0.0413  F: 0.0040\n",
      "Epoch: 6300 - KL: 0.1938  Rec: 0.5354  CosSim: 0.0421  F: 0.0038\n",
      "Epoch: 6400 - KL: 0.1941  Rec: 0.5423  CosSim: 0.0423  F: 0.0039\n",
      "Epoch: 6500 - KL: 0.1847  Rec: 0.5422  CosSim: 0.0436  F: 0.0040\n",
      "epoch:[6500/10000]: loss:0.774493\n",
      "Epoch: 6600 - KL: 0.1860  Rec: 0.5357  CosSim: 0.0432  F: 0.0038\n",
      "Finished Mapping!\n",
      "Setup: 0.4890375020040665\n",
      "Get subset samples: 0.0017728781161994894\n",
      "Run model: 0.01793273265440648\n",
      "KL Loss: 0.00033577568685192323\n",
      "Reconstruction Loss: 0.0002764063910649009\n",
      "Difference calculation: 0.001649165085785804\n",
      "Cosine Loss: 0.00014970366351376354\n",
      "F Loss: 0.00012893313589318092\n",
      "Step: 0.04880061775646066\n",
      "Output: 0.014530781001667492\n",
      "Total: 0.57461449549591\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 0.2528095729940105\n",
      "Distance Memory: Stored 4164813 - Peak 6448653\n",
      "Correspondence: 11.520646809993195\n",
      "Correspondence Memory: Stored 1009492 - Peak 4001195\n",
      "Mapping: 470.11652596699423\n",
      "Mapping Memory: Stored 25066848 - Peak 62105771\n",
      "Total: 481.88998234998144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedecc8-d72a-4788-a391-ccac6d27eabc",
   "metadata": {},
   "source": [
    "# scMNC Motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "649c0247-23a2-4cd7-9eed-d646e336bc1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'scMNC-Motor'\n",
    "dataset_color = 'sienna'\n",
    "modality_names = ['Gene Expression', 'Electrophysiology']\n",
    "data_folder = '../data/scMNC/mouse_motor_cortex/data/'\n",
    "data1 = pd.read_csv(data_folder + \"geneExp_filtered.csv\")\n",
    "data2 = pd.read_csv(data_folder + \"efeature_filtered.csv\")\n",
    "feat1 = np.array(data1.iloc[:, 0])\n",
    "feat2 = np.array(data2.columns)\n",
    "sample_names1 = data1.columns[1:]\n",
    "assert ((data1.shape[1] - 1) == data2.shape[0])\n",
    "data1 = np.transpose(np.array(data1)[:, 1:])\n",
    "data2 = np.array(data2)\n",
    "meta = pd.read_excel(data_folder + \"motor_meta_data.xlsx\")[['Cell', 'RNA family']]\n",
    "meta = np.array(meta)\n",
    "meta_idx = [np.argwhere(meta[:, 0] == sample_names1[i])[0][0] for i in range(sample_names1.shape[0])]\n",
    "type1 = type2 = np.array([x.split()[0] for x in meta[meta_idx, 1]])\n",
    "\n",
    "# Sampling\n",
    "# split = 1000 # data1.shape[0]\n",
    "# data_col_idx = np.random.choice(range(data1.shape[0]), split, replace=False)\n",
    "# data1, data2, type1, type2 = (x[data_col_idx] for x in (data1, data2, type1, type2))\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [feat1, feat2]\n",
    "feature_dict = {}\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "466c6d49-89ed-459d-aeff-86d4e929a6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c06c1ad-7f39-4902-906b-ce4a494f506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (1208, 1286)\n",
      "Dataset 1: (1208, 29)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:0.3861 alpha:0.0050\n",
      "epoch:[1000/2000] err:3.3359 alpha:0.0249\n",
      "epoch:[1500/2000] err:5.7469 alpha:0.0598\n",
      "epoch:[2000/2000] err:7.0837 alpha:0.0926\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:427: UserWarning: PCA dim must be lower than 29, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 - KL: 0.0007  Rec: 1.7173  CosSim: 1.3189  F: 0.0223\n",
      "Epoch: 200 - KL: 0.0029  Rec: 1.6833  CosSim: 0.3699  F: 0.0063\n",
      "Epoch: 300 - KL: 0.0045  Rec: 1.4586  CosSim: 0.1846  F: 0.0035\n",
      "Epoch: 400 - KL: 0.0076  Rec: 1.4519  CosSim: 0.1341  F: 0.0028\n",
      "Epoch: 500 - KL: 0.0099  Rec: 1.4924  CosSim: 0.0905  F: 0.0023\n",
      "epoch:[500/10000]: loss:1.512238\n",
      "Epoch: 600 - KL: 0.0183  Rec: 1.3405  CosSim: 0.0826  F: 0.0020\n",
      "Epoch: 700 - KL: 0.0260  Rec: 1.3499  CosSim: 0.0944  F: 0.0020\n",
      "Epoch: 800 - KL: 0.0441  Rec: 1.3492  CosSim: 0.0684  F: 0.0017\n",
      "Epoch: 900 - KL: 0.0733  Rec: 1.3068  CosSim: 0.0543  F: 0.0016\n",
      "Epoch: 1000 - KL: 0.0943  Rec: 1.1985  CosSim: 0.0617  F: 0.0016\n",
      "epoch:[1000/10000]: loss:1.345666\n",
      "Epoch: 1100 - KL: 0.1174  Rec: 1.2670  CosSim: 0.0648  F: 0.0018\n",
      "Epoch: 1200 - KL: 0.1444  Rec: 1.2078  CosSim: 0.0632  F: 0.0016\n",
      "Epoch: 1300 - KL: 0.2010  Rec: 1.1388  CosSim: 0.0661  F: 0.0016\n",
      "Epoch: 1400 - KL: 0.1848  Rec: 1.1798  CosSim: 0.0663  F: 0.0016\n",
      "Epoch: 1500 - KL: 0.1324  Rec: 1.3001  CosSim: 0.0716  F: 0.0015\n",
      "epoch:[1500/10000]: loss:1.501870\n",
      "Epoch: 1600 - KL: 0.2385  Rec: 1.1944  CosSim: 0.0751  F: 0.0015\n",
      "Epoch: 1700 - KL: 0.2152  Rec: 1.1554  CosSim: 0.0628  F: 0.0014\n",
      "Epoch: 1800 - KL: 0.1915  Rec: 1.1759  CosSim: 0.0744  F: 0.0014\n",
      "Epoch: 1900 - KL: 0.2715  Rec: 1.1155  CosSim: 0.0691  F: 0.0014\n",
      "Epoch: 2000 - KL: 0.1835  Rec: 1.0904  CosSim: 0.0683  F: 0.0013\n",
      "epoch:[2000/10000]: loss:1.374745\n",
      "Epoch: 2100 - KL: 0.1796  Rec: 1.1898  CosSim: 0.0717  F: 0.0014\n",
      "Epoch: 2200 - KL: 0.1495  Rec: 1.2181  CosSim: 0.0810  F: 0.0013\n",
      "Epoch: 2300 - KL: 0.2270  Rec: 1.0846  CosSim: 0.0750  F: 0.0011\n",
      "Epoch: 2400 - KL: 0.1917  Rec: 1.1264  CosSim: 0.0749  F: 0.0013\n",
      "Epoch: 2500 - KL: 0.3087  Rec: 1.1662  CosSim: 0.0771  F: 0.0013\n",
      "epoch:[2500/10000]: loss:1.498230\n",
      "Epoch: 2600 - KL: 0.2342  Rec: 1.0478  CosSim: 0.0834  F: 0.0015\n",
      "Epoch: 2700 - KL: 0.1485  Rec: 1.0484  CosSim: 0.0650  F: 0.0010\n",
      "Epoch: 2800 - KL: 0.1039  Rec: 1.1683  CosSim: 0.0828  F: 0.0014\n",
      "Epoch: 2900 - KL: 0.1947  Rec: 1.0679  CosSim: 0.0716  F: 0.0011\n",
      "Epoch: 3000 - KL: 0.2208  Rec: 1.0548  CosSim: 0.0802  F: 0.0014\n",
      "epoch:[3000/10000]: loss:1.347859\n",
      "Epoch: 3100 - KL: 0.2196  Rec: 1.1205  CosSim: 0.0683  F: 0.0011\n",
      "Epoch: 3200 - KL: 0.2195  Rec: 1.1220  CosSim: 0.0753  F: 0.0012\n",
      "Epoch: 3300 - KL: 0.2315  Rec: 1.0491  CosSim: 0.0594  F: 0.0009\n",
      "Epoch: 3400 - KL: 0.3086  Rec: 1.0814  CosSim: 0.0640  F: 0.0010\n",
      "Epoch: 3500 - KL: 0.1889  Rec: 1.0372  CosSim: 0.0678  F: 0.0012\n",
      "epoch:[3500/10000]: loss:1.288123\n",
      "Epoch: 3600 - KL: 0.2337  Rec: 1.0948  CosSim: 0.0553  F: 0.0008\n",
      "Epoch: 3700 - KL: 0.1766  Rec: 1.1180  CosSim: 0.0595  F: 0.0011\n",
      "Epoch: 3800 - KL: 0.2863  Rec: 1.1138  CosSim: 0.0595  F: 0.0010\n",
      "Finished Mapping!\n",
      "Setup: 1.3002126819919795\n",
      "Get subset samples: 0.0022522490615652867\n",
      "Run model: 0.011469613155808338\n",
      "KL Loss: 0.00030914681197498735\n",
      "Reconstruction Loss: 0.00023105216773351234\n",
      "Difference calculation: 0.001645107447027717\n",
      "Cosine Loss: 0.00015205619909211895\n",
      "F Loss: 0.00016089036192517813\n",
      "Step: 0.030004882458277714\n",
      "Output: 0.02486863599915523\n",
      "Total: 1.3713063156545395\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 1.4497346470016055\n",
      "Distance Memory: Stored 23526229 - Peak 36738729\n",
      "Correspondence: 170.63873534099548\n",
      "Correspondence Memory: Stored 5858486 - Peak 23349419\n",
      "Mapping: 354.4411127850035\n",
      "Mapping Memory: Stored 11382592 - Peak 43898151\n",
      "Total: 526.5295827730006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f5571-540c-44d4-942a-78d343134476",
   "metadata": {},
   "source": [
    "# scMNC Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95000a46-6f3d-4be3-9c8a-44a70c0b6897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'scMNC-Visual'\n",
    "dataset_color = 'magenta'\n",
    "modality_names = ['Gene Expression', 'Electrophysiology']\n",
    "data_folder = '../data/scMNC/mouse_visual_cortex/data/'\n",
    "data1 = pd.read_csv(data_folder + \"geneExp_filtered.csv\")\n",
    "data2 = pd.read_csv(data_folder + \"efeature_filtered.csv\")\n",
    "sample_names1 = data1.columns[1:]\n",
    "sample_names2 = np.array(data2)[:, 0]\n",
    "feature_names1 = data1.iloc[:,0]\n",
    "feature_names2 = data2.columns[3:]\n",
    "assert (sample_names1 == sample_names2).all()\n",
    "data1 = np.transpose(np.array(data1)[:, 1:])\n",
    "data2 = np.array(data2)[:, 3:]\n",
    "meta = pd.read_csv(data_folder + \"20200711_patchseq_metadata_mouse.csv\")[['transcriptomics_sample_id', 't_type']]\n",
    "meta = np.array(meta)\n",
    "meta_idx = [np.argwhere(meta[:, 0] == sample_names1[i])[0][0] for i in range(sample_names1.shape[0])]\n",
    "type1 = type2 = np.array([x.split(' ')[0] for x in meta[meta_idx, 1]])\n",
    "\n",
    "# Sampling\n",
    "# split = 1000 # data1.shape[0]\n",
    "# data_col_idx = np.random.choice(range(data1.shape[0]), split, replace=False)\n",
    "# data1, data2, type1, type2 = (x[data_col_idx] for x in (data1, data2, type1, type2))\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [np.array(feature_names1), np.array(feature_names2)]\n",
    "feature_dict = {}\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "790ad528-85db-40f9-82d9-585e792985cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bde8e0f1-ef29-490c-b06e-e4c1da15bf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (3654, 1302)\n",
      "Dataset 1: (3654, 39)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:0.4526 alpha:0.0207\n",
      "epoch:[1000/2000] err:0.0000 alpha:0.0000\n",
      "epoch:[1500/2000] err:0.0000 alpha:0.0000\n",
      "epoch:[2000/2000] err:0.0000 alpha:0.0000\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/nck/repos/nmacom/jamie/jamie.py:427: UserWarning: PCA dim must be lower than 39, found 512, adjusting to compensate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 - KL: 0.0027  Rec: 1.4028  CosSim: 0.0921  F: 0.0023\n",
      "Epoch: 200 - KL: 0.0040  Rec: 1.2102  CosSim: 0.0425  F: 0.0015\n",
      "Epoch: 300 - KL: 0.0061  Rec: 1.1673  CosSim: 0.0318  F: 0.0012\n",
      "Epoch: 400 - KL: 0.0128  Rec: 1.1311  CosSim: 0.0284  F: 0.0009\n",
      "Epoch: 500 - KL: 0.0231  Rec: 1.2293  CosSim: 0.0237  F: 0.0009\n",
      "epoch:[500/10000]: loss:1.293293\n",
      "Epoch: 600 - KL: 0.0261  Rec: 1.3639  CosSim: 0.0233  F: 0.0009\n",
      "Epoch: 700 - KL: 0.0365  Rec: 1.2801  CosSim: 0.0328  F: 0.0010\n",
      "Epoch: 800 - KL: 0.0487  Rec: 1.1628  CosSim: 0.0269  F: 0.0008\n",
      "Epoch: 900 - KL: 0.0622  Rec: 1.1354  CosSim: 0.0258  F: 0.0008\n",
      "Epoch: 1000 - KL: 0.0842  Rec: 1.1176  CosSim: 0.0255  F: 0.0007\n",
      "epoch:[1000/10000]: loss:1.209488\n",
      "Epoch: 1100 - KL: 0.0747  Rec: 1.0409  CosSim: 0.0271  F: 0.0007\n",
      "Epoch: 1200 - KL: 0.1079  Rec: 1.0813  CosSim: 0.0291  F: 0.0007\n",
      "Epoch: 1300 - KL: 0.1372  Rec: 1.0874  CosSim: 0.0340  F: 0.0007\n",
      "Epoch: 1400 - KL: 0.1532  Rec: 1.1358  CosSim: 0.0403  F: 0.0007\n",
      "Epoch: 1500 - KL: 0.1515  Rec: 1.1154  CosSim: 0.0406  F: 0.0007\n",
      "epoch:[1500/10000]: loss:1.313457\n",
      "Epoch: 1600 - KL: 0.1464  Rec: 1.0788  CosSim: 0.0410  F: 0.0006\n",
      "Epoch: 1700 - KL: 0.1663  Rec: 1.1067  CosSim: 0.0460  F: 0.0008\n",
      "Epoch: 1800 - KL: 0.1767  Rec: 1.0596  CosSim: 0.0403  F: 0.0006\n",
      "Epoch: 1900 - KL: 0.1731  Rec: 1.0847  CosSim: 0.0403  F: 0.0006\n",
      "Epoch: 2000 - KL: 0.1913  Rec: 1.1234  CosSim: 0.0404  F: 0.0005\n",
      "epoch:[2000/10000]: loss:1.372675\n",
      "Epoch: 2100 - KL: 0.1859  Rec: 1.1843  CosSim: 0.0413  F: 0.0007\n",
      "Epoch: 2200 - KL: 0.1800  Rec: 1.0784  CosSim: 0.0407  F: 0.0006\n",
      "Epoch: 2300 - KL: 0.1832  Rec: 1.1107  CosSim: 0.0418  F: 0.0006\n",
      "Epoch: 2400 - KL: 0.1871  Rec: 1.0587  CosSim: 0.0401  F: 0.0007\n",
      "Epoch: 2500 - KL: 0.1886  Rec: 1.1218  CosSim: 0.0376  F: 0.0006\n",
      "epoch:[2500/10000]: loss:1.329161\n",
      "Epoch: 2600 - KL: 0.1858  Rec: 1.0183  CosSim: 0.0393  F: 0.0006\n",
      "Epoch: 2700 - KL: 0.1905  Rec: 1.0522  CosSim: 0.0397  F: 0.0007\n",
      "Epoch: 2800 - KL: 0.1902  Rec: 1.1123  CosSim: 0.0423  F: 0.0010\n",
      "Epoch: 2900 - KL: 0.1892  Rec: 1.0521  CosSim: 0.0373  F: 0.0007\n",
      "Epoch: 3000 - KL: 0.1885  Rec: 1.0116  CosSim: 0.0384  F: 0.0006\n",
      "epoch:[3000/10000]: loss:1.282193\n",
      "Epoch: 3100 - KL: 0.1899  Rec: 1.0726  CosSim: 0.0371  F: 0.0006\n",
      "Epoch: 3200 - KL: 0.1911  Rec: 1.0545  CosSim: 0.0390  F: 0.0006\n",
      "Epoch: 3300 - KL: 0.1909  Rec: 1.0418  CosSim: 0.0383  F: 0.0007\n",
      "Epoch: 3400 - KL: 0.1895  Rec: 1.0009  CosSim: 0.0383  F: 0.0006\n",
      "Finished Mapping!\n",
      "Setup: 2.5606292610027594\n",
      "Get subset samples: 0.00508428682347833\n",
      "Run model: 0.011445385519127766\n",
      "KL Loss: 0.00030789014551661656\n",
      "Reconstruction Loss: 0.00022509308800322276\n",
      "Difference calculation: 0.0016157533813198695\n",
      "Cosine Loss: 0.00015029045992659057\n",
      "F Loss: 0.00016040117754828368\n",
      "Step: 0.027916605446312446\n",
      "Output: 0.10551218400360085\n",
      "Total: 2.713047151047593\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 39.910873287008144\n",
      "Distance Memory: Stored 213786730 - Peak 334187882\n",
      "Correspondence: 4465.036841956011\n",
      "Correspondence Memory: Stored 53467458 - Peak 213628651\n",
      "Mapping: 1124.7604935900017\n",
      "Mapping Memory: Stored 22471844 - Peak 235707387\n",
      "Total: 5629.708208833021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacab1a8-b775-423e-9a5f-7a930c70d473",
   "metadata": {},
   "source": [
    "# DM_rep4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f673b8f-7815-494f-bc7a-1b1e6d698502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/miniconda3/lib/python3.9/site-packages/anndata/compat/__init__.py:232: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/anndata/compat/__init__.py:232: FutureWarning: Moving element from .uns['neighbors']['connectivities'] to .obsp['connectivities'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/anndata/compat/__init__.py:232: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/anndata/compat/__init__.py:232: FutureWarning: Moving element from .uns['neighbors']['connectivities'] to .obsp['connectivities'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "babel_dir = '../data/babel_data/DM_rep4/'\n",
    "train = sc.read_h5ad(babel_dir + 'train_rna.h5ad')\n",
    "v = train.var_names\n",
    "train = train.X.toarray()\n",
    "valid = sc.read_h5ad(babel_dir + 'truth_rna.h5ad').X.toarray()\n",
    "data1 = np.concatenate([train, valid], axis=0)\n",
    "fnames1 = np.array(v)\n",
    "\n",
    "train = sc.read_h5ad(babel_dir + 'train_atac.h5ad')\n",
    "v = train.var_names\n",
    "train = train.X.toarray()\n",
    "valid = sc.read_h5ad(babel_dir + 'truth_atac.h5ad').X.toarray()\n",
    "data2 = np.concatenate([train, valid], axis=0)\n",
    "fnames2 = np.array(v)\n",
    "\n",
    "split = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda7b4c1-7472-437f-a23f-b849f2fe9623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'DM_rep4'\n",
    "dataset_color = 'black'\n",
    "modality_names = ['RNA', 'ATAC']\n",
    "\n",
    "# data1 = PCA(n_components=32).fit_transform(data1)\n",
    "# data2 = PCA(n_components=32).fit_transform(data2)\n",
    "# fnames1 = fnames2 = None\n",
    "\n",
    "type1 = np.array(len(data1) * ['Cell Type 0'])\n",
    "type2 = np.array(len(data2) * ['Cell Type 0'])\n",
    "\n",
    "# Sampling\n",
    "# sample_num = 500\n",
    "# data_col_idx = np.random.choice(range(split), sample_num, replace=False)\n",
    "# data1, data2, type1, type2 = (x[list(data_col_idx) + list(range(split, len(data1)))] for x in (data1, data2, type1, type2))\n",
    "# split = sample_num\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [np.array(fnames1), np.array(fnames2)]\n",
    "feature_dict = {}\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5733050e-4c08-475b-b5d5-497e2220e2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:254: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:254: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# # Train-Test Imputation\n",
    "train_size = split\n",
    "train_idx = np.array(range(split))\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2afce45f-579a-4e29-8e5e-3a93b07c1515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (4301, 34861)\n",
      "Dataset 1: (4301, 85596)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:3240.7747 alpha:318.6570\n",
      "epoch:[1000/2000] err:202.1322 alpha:18.4804\n",
      "epoch:[1500/2000] err:0.6152 alpha:0.0076\n",
      "epoch:[2000/2000] err:0.0001 alpha:0.0000\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n",
      "Epoch: 100 - KL: 0.0026  Rec: 1.8253  CosSim: 0.0447  F: 0.0020\n",
      "Epoch: 200 - KL: 0.0046  Rec: 1.8538  CosSim: 0.0469  F: 0.0033\n",
      "Epoch: 300 - KL: 0.0065  Rec: 1.6934  CosSim: 0.0374  F: 0.0035\n",
      "Epoch: 400 - KL: 0.0089  Rec: 1.4560  CosSim: 0.0336  F: 0.0026\n",
      "Epoch: 500 - KL: 0.0147  Rec: 1.5693  CosSim: 0.0241  F: 0.0016\n",
      "epoch:[500/10000]: loss:1.573188\n",
      "Epoch: 600 - KL: 0.0205  Rec: 1.6335  CosSim: 0.0203  F: 0.0018\n",
      "Epoch: 700 - KL: 0.0304  Rec: 1.5816  CosSim: 0.0277  F: 0.0036\n",
      "Epoch: 800 - KL: 0.0393  Rec: 1.4780  CosSim: 0.0256  F: 0.0015\n",
      "Epoch: 900 - KL: 0.0432  Rec: 1.4849  CosSim: 0.0220  F: 0.0015\n",
      "Epoch: 1000 - KL: 0.0642  Rec: 1.4868  CosSim: 0.0247  F: 0.0047\n",
      "epoch:[1000/10000]: loss:1.543855\n",
      "Epoch: 1100 - KL: 0.0905  Rec: 1.2654  CosSim: 0.0284  F: 0.0057\n",
      "Epoch: 1200 - KL: 0.0895  Rec: 1.2196  CosSim: 0.0301  F: 0.0021\n",
      "Epoch: 1300 - KL: 0.1150  Rec: 1.3097  CosSim: 0.0329  F: 0.0022\n",
      "Epoch: 1400 - KL: 0.1413  Rec: 1.5665  CosSim: 0.0355  F: 0.0015\n",
      "Epoch: 1500 - KL: 0.1502  Rec: 1.5094  CosSim: 0.0378  F: 0.0022\n",
      "epoch:[1500/10000]: loss:1.579976\n",
      "Epoch: 1600 - KL: 0.1606  Rec: 1.3115  CosSim: 0.0398  F: 0.0029\n",
      "Epoch: 1700 - KL: 0.1660  Rec: 1.3677  CosSim: 0.0415  F: 0.0019\n",
      "Epoch: 1800 - KL: 0.1897  Rec: 1.3603  CosSim: 0.0390  F: 0.0021\n",
      "Epoch: 1900 - KL: 0.1858  Rec: 1.1950  CosSim: 0.0416  F: 0.0044\n",
      "Epoch: 2000 - KL: 0.1670  Rec: 1.2291  CosSim: 0.0468  F: 0.0028\n",
      "epoch:[2000/10000]: loss:1.585841\n",
      "Epoch: 2100 - KL: 0.2032  Rec: 1.3655  CosSim: 0.0439  F: 0.0021\n",
      "Epoch: 2200 - KL: 0.1832  Rec: 1.3770  CosSim: 0.0421  F: 0.0016\n",
      "Epoch: 2300 - KL: 0.1709  Rec: 1.3135  CosSim: 0.0439  F: 0.0019\n",
      "Epoch: 2400 - KL: 0.2050  Rec: 1.2620  CosSim: 0.0426  F: 0.0018\n",
      "Epoch: 2500 - KL: 0.1929  Rec: 1.4263  CosSim: 0.0434  F: 0.0021\n",
      "epoch:[2500/10000]: loss:1.551058\n",
      "Epoch: 2600 - KL: 0.1831  Rec: 1.3746  CosSim: 0.0389  F: 0.0016\n",
      "Epoch: 2700 - KL: 0.1806  Rec: 1.1766  CosSim: 0.0441  F: 0.0020\n",
      "Epoch: 2800 - KL: 0.2091  Rec: 1.2774  CosSim: 0.0406  F: 0.0015\n",
      "Epoch: 2900 - KL: 0.1814  Rec: 1.3524  CosSim: 0.0394  F: 0.0024\n",
      "Epoch: 3000 - KL: 0.1818  Rec: 1.3305  CosSim: 0.0425  F: 0.0021\n",
      "epoch:[3000/10000]: loss:1.521782\n",
      "Epoch: 3100 - KL: 0.1820  Rec: 1.4523  CosSim: 0.0413  F: 0.0035\n",
      "Epoch: 3200 - KL: 0.1905  Rec: 1.1383  CosSim: 0.0418  F: 0.0017\n",
      "Epoch: 3300 - KL: 0.1785  Rec: 1.4412  CosSim: 0.0386  F: 0.0014\n",
      "Finished Mapping!\n",
      "Setup: 47.28184818298905\n",
      "Get subset samples: 0.006221037192290715\n",
      "Run model: 0.019820612141505586\n",
      "KL Loss: 0.0003534187935366836\n",
      "Reconstruction Loss: 0.0003051101643014074\n",
      "Difference calculation: 0.0017282755590862019\n",
      "Cosine Loss: 0.00015730044144281517\n",
      "F Loss: 0.0001630780089538593\n",
      "Step: 0.05338524741537917\n",
      "Output: 0.22257583399186842\n",
      "Total: 47.586558096697416\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 210.30842608200328\n",
      "Distance Memory: Stored 296175714 - Peak 5410346423\n",
      "Correspondence: 7119.5121463960095\n",
      "Correspondence Memory: Stored 74065822 - Peak 295978811\n",
      "Mapping: 2235.2330217099952\n",
      "Mapping Memory: Stored 288179840 - Peak 3215879624\n",
      "Total: 9565.053594188008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3baf07c-6d3b-4a7e-98de-65cd7b603779",
   "metadata": {},
   "source": [
    "# brainchromatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57576f1c-063f-4664-a954-ed998aa04a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'BrainChromatin'\n",
    "dataset_color = 'orange'\n",
    "modality_names = ['RNA', 'ATAC']\n",
    "data_folder = '../data/brainchromatin/'\n",
    "data1 = pd.read_csv(data_folder + \"multiome_rna_counts.tsv\", delimiter='\\t').transpose()\n",
    "data2 = pd.read_csv(data_folder + \"multiome_atac_gene_activities.tsv\", delimiter='\\t', nrows=35000).transpose()\n",
    "data2 = data2.transpose()[data1.index].transpose()\n",
    "\n",
    "meta = pd.read_csv(data_folder + \"multiome_cell_metadata.txt\", delimiter='\\t')\n",
    "meta_names = pd.read_csv(data_folder + \"multiome_cluster_names.txt\", delimiter='\\t')\n",
    "meta_names = meta_names[meta_names['Assay'] == 'Multiome ATAC']\n",
    "meta = pd.merge(meta, meta_names, left_on='ATAC_cluster', right_on='Cluster.ID', how='left')\n",
    "meta.index = meta['Cell.ID']\n",
    "\n",
    "type1 = type2 = np.array(meta.transpose()[data1.index].transpose()['Cluster.Name'])\n",
    "fname1, fname2 = data1.columns, data2.columns\n",
    "data1 = data1.to_numpy()\n",
    "data2 = data2.to_numpy()\n",
    "\n",
    "# Sampling\n",
    "split = 4000 # data1.shape[0]\n",
    "data_row_idx = np.random.choice(range(data1.shape[0]), split, replace=False)\n",
    "# data1, data2, type1, type2 = (x[data_row_idx] for x in (data1, data2, type1, type2))\n",
    "# split_feat_1 = 2000 # data1.shape[1]\n",
    "# data_col1_idx = np.random.choice(range(data1.shape[1]), split_feat_1, replace=False)\n",
    "# data1, fname1 = data1[:, data_col1_idx], fname1[data_col1_idx]\n",
    "# split_feat_2 = 2000 # data2.shape[1]\n",
    "# data_col2_idx = np.random.choice(range(data2.shape[1]), split_feat_2, replace=False)\n",
    "# data2, fname2 = data2[:, data_col2_idx], fname2[data_col2_idx]\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [np.array(fname1), np.array(fname2)]\n",
    "feature_dict = {'ENSG00000251562': 'MALAT1', 'ENSG00000153707': 'PTPRD'}\n",
    "\n",
    "# Utility\n",
    "positivize = lambda X: [x + x.min() for x in X]\n",
    "minmax = lambda X: [(x + x.min()) for x in X]\n",
    "\n",
    "# Change Labels\n",
    "group = ['GluN3', 'GluN4', 'IN1', 'GluN2', 'IN2', 'GluN6', 'GluN5', 'RG',\n",
    "       'nIPC', 'GluN1', 'mGPC/OPC', 'IN3', 'IN4', 'SP', 'GluN7',\n",
    "       'MG/EC/Peric.']\n",
    "conv =  ['GluN', 'GluN', 'IN', 'GluN', 'IN', 'GluN', 'GluN', 'RG',\n",
    "        'nIPC', 'GluN', 'mGPC/OPC', 'IN', 'IN', 'SP', 'GluN',\n",
    "        'MG/EC/Peric.']\n",
    "group_conv = {g:c for g, c in zip(group, conv)}\n",
    "labels = [np.array([group_conv[l] for l in label]) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c8229c8-e313-44f6-986c-6c8743fceb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d732e49-2d1a-4050-a6f7-22f0bbebf1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (8981, 34104)\n",
      "Dataset 1: (8981, 19836)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:1774.8389 alpha:23.8913\n",
      "epoch:[1000/2000] err:324.3965 alpha:0.0213\n",
      "epoch:[1500/2000] err:152.1128 alpha:0.0015\n",
      "epoch:[2000/2000] err:67.9232 alpha:0.0002\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n",
      "Epoch: 100 - KL: 0.0026  Rec: 1.7848  CosSim: 0.0364  F: 0.0016\n",
      "Epoch: 200 - KL: 0.0050  Rec: 1.3758  CosSim: 0.0223  F: 0.0013\n",
      "Epoch: 300 - KL: 0.0063  Rec: 1.6501  CosSim: 0.0245  F: 0.0011\n",
      "Epoch: 400 - KL: 0.0101  Rec: 1.3823  CosSim: 0.0135  F: 0.0006\n",
      "Epoch: 500 - KL: 0.0127  Rec: 1.6549  CosSim: 0.0118  F: 0.0005\n",
      "epoch:[500/10000]: loss:1.522530\n",
      "Epoch: 600 - KL: 0.0182  Rec: 1.3020  CosSim: 0.0128  F: 0.0006\n",
      "Epoch: 700 - KL: 0.0282  Rec: 1.5264  CosSim: 0.0158  F: 0.0008\n",
      "Epoch: 800 - KL: 0.0357  Rec: 1.2886  CosSim: 0.0141  F: 0.0006\n",
      "Epoch: 900 - KL: 0.0445  Rec: 1.3990  CosSim: 0.0154  F: 0.0006\n",
      "Epoch: 1000 - KL: 0.0595  Rec: 1.4619  CosSim: 0.0185  F: 0.0008\n",
      "epoch:[1000/10000]: loss:1.496978\n",
      "Epoch: 1100 - KL: 0.0870  Rec: 1.4766  CosSim: 0.0186  F: 0.0007\n",
      "Epoch: 1200 - KL: 0.0975  Rec: 1.5641  CosSim: 0.0244  F: 0.0009\n",
      "Epoch: 1300 - KL: 0.1215  Rec: 1.2951  CosSim: 0.0269  F: 0.0009\n",
      "Epoch: 1400 - KL: 0.1281  Rec: 1.3090  CosSim: 0.0264  F: 0.0008\n",
      "Epoch: 1500 - KL: 0.1407  Rec: 1.3963  CosSim: 0.0318  F: 0.0009\n",
      "epoch:[1500/10000]: loss:1.595425\n",
      "Epoch: 1600 - KL: 0.1538  Rec: 1.5135  CosSim: 0.0348  F: 0.0012\n",
      "Epoch: 1700 - KL: 0.1716  Rec: 1.3487  CosSim: 0.0336  F: 0.0010\n",
      "Epoch: 1800 - KL: 0.1633  Rec: 1.2689  CosSim: 0.0338  F: 0.0011\n",
      "Epoch: 1900 - KL: 0.1696  Rec: 1.5460  CosSim: 0.0362  F: 0.0013\n",
      "Epoch: 2000 - KL: 0.1716  Rec: 1.4012  CosSim: 0.0389  F: 0.0012\n",
      "epoch:[2000/10000]: loss:1.566096\n",
      "Epoch: 2100 - KL: 0.1717  Rec: 1.3601  CosSim: 0.0384  F: 0.0010\n",
      "Epoch: 2200 - KL: 0.1785  Rec: 1.2758  CosSim: 0.0379  F: 0.0011\n",
      "Epoch: 2300 - KL: 0.1818  Rec: 1.3600  CosSim: 0.0393  F: 0.0010\n",
      "Epoch: 2400 - KL: 0.1848  Rec: 1.2022  CosSim: 0.0357  F: 0.0009\n",
      "Epoch: 2500 - KL: 0.1819  Rec: 1.3519  CosSim: 0.0368  F: 0.0010\n",
      "epoch:[2500/10000]: loss:1.555277\n",
      "Epoch: 2600 - KL: 0.1789  Rec: 1.3331  CosSim: 0.0387  F: 0.0011\n",
      "Epoch: 2700 - KL: 0.1794  Rec: 1.2861  CosSim: 0.0398  F: 0.0012\n",
      "Epoch: 2800 - KL: 0.1864  Rec: 1.3055  CosSim: 0.0381  F: 0.0011\n",
      "Epoch: 2900 - KL: 0.1808  Rec: 1.3414  CosSim: 0.0400  F: 0.0013\n",
      "Epoch: 3000 - KL: 0.1792  Rec: 1.2146  CosSim: 0.0393  F: 0.0012\n",
      "epoch:[3000/10000]: loss:1.552067\n",
      "Epoch: 3100 - KL: 0.1801  Rec: 1.4435  CosSim: 0.0374  F: 0.0011\n",
      "Finished Mapping!\n",
      "Setup: 109.35217695700703\n",
      "Get subset samples: 0.01235380867979595\n",
      "Run model: 0.019786308046955674\n",
      "KL Loss: 0.0003552514031151642\n",
      "Reconstruction Loss: 0.00029960271020094086\n",
      "Difference calculation: 0.0017472010852783587\n",
      "Cosine Loss: 0.0001550342891556252\n",
      "F Loss: 0.00016588872990470305\n",
      "Step: 0.05335419626948821\n",
      "Output: 0.552738380007213\n",
      "Total: 109.99313262822814\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 708.7241217489936\n",
      "Distance Memory: Stored 1290697003 - Peak 2017198916\n",
      "Correspondence: 43868.482073216\n",
      "Correspondence Memory: Stored 322778181 - Peak 1290538407\n",
      "Mapping: 4795.5422309190035\n",
      "Mapping Memory: Stored 301280686 - Peak 5081428501\n",
      "Total: 49372.748425884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262373c-771f-4b78-bd49-6165bc2ceb2e",
   "metadata": {},
   "source": [
    "# scGLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61c00ce-65b8-4c25-98fb-45d56ba3dea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6636863-1a27-4570-9aa5-c8418b4e71e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "dataset_name = 'scGLUE'\n",
    "dataset_color = 'yellow'\n",
    "modality_names = ['RNA', 'ATAC']\n",
    "data_folder = '../data/scGLUE/'\n",
    "\n",
    "data1 = sc.read_h5ad(data_folder + 'Chen-2019-RNA.h5ad')\n",
    "type1 = data1.obs.cell_type.to_numpy()\n",
    "fname1 = data1.var.name.to_numpy()\n",
    "data1 = data1.X.todense()\n",
    "\n",
    "data2 = sc.read_h5ad(data_folder + 'Chen-2019-ATAC.h5ad')\n",
    "type2 = data2.obs.cell_type.to_numpy()\n",
    "fname2 = data2.var.index.to_numpy()\n",
    "data2 = data2.X.todense()\n",
    "\n",
    "# Labels\n",
    "labels = [type1, type2]\n",
    "features = [fname1, fname2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf9e1c5-743c-4f07-999e-c18120ad6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:254: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:235: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\n",
      "/home/thema/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:254: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "data1 = preprocessing.scale(data1, axis=0)\n",
    "data2 = preprocessing.scale(data2, axis=0)\n",
    "data1[np.isnan(data1)] = 0  # Replace NaN with average\n",
    "data2[np.isnan(data2)] = 0\n",
    "# data1 = preprocessing.MinMaxScaler().fit_transform(data1)\n",
    "# data2 = preprocessing.MinMaxScaler().fit_transform(data2)\n",
    "dataset = [data1, data2]\n",
    "\n",
    "# Replace NULL feature names\n",
    "for i in range(len(features)):\n",
    "    if features[i] is None:\n",
    "        features[i] = np.array([f'Feature {i}' for i in range(dataset[i].shape[1])])\n",
    "        \n",
    "# Train-Test Imputation\n",
    "train_size = int(.8 * len(data1))\n",
    "train_idx = np.random.choice(range(len(data1)), train_size, replace=False)\n",
    "test_idx = np.array(list(set(range(len(data1))) - set(train_idx)))\n",
    "\n",
    "# Reduced Priors\n",
    "full_priors = np.eye(len(dataset[0]))\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.5 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "half_priors = np.diag(priors)\n",
    "random_idx = np.random.choice(range(len(dataset[0])), int(.75 * len(dataset[0])), replace=False)\n",
    "priors = np.zeros(len(dataset[0]))\n",
    "priors[random_idx] = 1\n",
    "tq_priors = np.diag(priors)\n",
    "none_priors = np.zeros((len(dataset[0]), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4518f6-8c58-4695-a919-97b5f12e8b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 666\n",
      "Shape of Raw data\n",
      "Dataset 0: (9190, 28930)\n",
      "Dataset 1: (9190, 241757)\n",
      "Device: cpu\n",
      "---------------------------------\n",
      "Find correspondence between Dataset 1 and Dataset 2\n",
      "epoch:[500/2000] err:31392.3984 alpha:3819.6143\n",
      "epoch:[1000/2000] err:8624.8457 alpha:1050.6832\n",
      "epoch:[1500/2000] err:2395.9426 alpha:291.6512\n",
      "epoch:[2000/2000] err:198.7031 alpha:16.8099\n",
      "Finished Matching!\n",
      "---------------------------------\n",
      "Train coupled autoencoders\n",
      "Epoch: 100 - KL: 0.0031  Rec: 1.7631  CosSim: 0.0261  F: 0.0012\n",
      "Epoch: 200 - KL: 0.0050  Rec: 2.0951  CosSim: 0.0218  F: 0.0010\n",
      "Epoch: 300 - KL: 0.0056  Rec: 1.9862  CosSim: 0.0123  F: 0.0005\n",
      "Epoch: 400 - KL: 0.0111  Rec: 1.8260  CosSim: 0.0171  F: 0.0007\n",
      "Epoch: 500 - KL: 0.0132  Rec: 1.3674  CosSim: 0.0134  F: 0.0005\n",
      "epoch:[500/10000]: loss:1.643861\n",
      "Epoch: 600 - KL: 0.0148  Rec: 1.6133  CosSim: 0.0156  F: 0.0006\n",
      "Epoch: 700 - KL: 0.0275  Rec: 1.7142  CosSim: 0.0167  F: 0.0006\n",
      "Epoch: 800 - KL: 0.0358  Rec: 1.9653  CosSim: 0.0153  F: 0.0005\n",
      "Epoch: 900 - KL: 0.0533  Rec: 1.5586  CosSim: 0.0165  F: 0.0005\n",
      "Epoch: 1000 - KL: 0.0591  Rec: 1.6029  CosSim: 0.0213  F: 0.0007\n",
      "epoch:[1000/10000]: loss:1.636264\n",
      "Epoch: 1100 - KL: 0.0766  Rec: 1.4071  CosSim: 0.0220  F: 0.0008\n",
      "Epoch: 1200 - KL: 0.0896  Rec: 1.4810  CosSim: 0.0220  F: 0.0006\n",
      "Epoch: 1300 - KL: 0.1119  Rec: 1.3068  CosSim: 0.0310  F: 0.0011\n",
      "Epoch: 1400 - KL: 0.1280  Rec: 1.3559  CosSim: 0.0299  F: 0.0008\n",
      "Epoch: 1500 - KL: 0.1409  Rec: 1.2110  CosSim: 0.0334  F: 0.0010\n",
      "epoch:[1500/10000]: loss:1.674927\n",
      "Epoch: 1600 - KL: 0.1541  Rec: 1.4869  CosSim: 0.0322  F: 0.0009\n",
      "Epoch: 1700 - KL: 0.1555  Rec: 1.7476  CosSim: 0.0326  F: 0.0008\n",
      "Epoch: 1800 - KL: 0.1647  Rec: 1.8555  CosSim: 0.0377  F: 0.0011\n",
      "Epoch: 1900 - KL: 0.1700  Rec: 1.4085  CosSim: 0.0373  F: 0.0010\n",
      "Epoch: 2000 - KL: 0.1703  Rec: 1.4087  CosSim: 0.0383  F: 0.0010\n",
      "epoch:[2000/10000]: loss:1.703260\n",
      "Epoch: 2100 - KL: 0.1741  Rec: 1.7607  CosSim: 0.0373  F: 0.0009\n",
      "Epoch: 2200 - KL: 0.1756  Rec: 1.6498  CosSim: 0.0358  F: 0.0008\n",
      "Epoch: 2300 - KL: 0.1771  Rec: 1.7432  CosSim: 0.0446  F: 0.0014\n",
      "Epoch: 2400 - KL: 0.1784  Rec: 1.3668  CosSim: 0.0395  F: 0.0011\n",
      "Epoch: 2500 - KL: 0.1805  Rec: 1.4197  CosSim: 0.0390  F: 0.0009\n",
      "epoch:[2500/10000]: loss:1.687663\n",
      "Epoch: 2600 - KL: 0.1756  Rec: 1.3329  CosSim: 0.0404  F: 0.0010\n",
      "Epoch: 2700 - KL: 0.1800  Rec: 1.2656  CosSim: 0.0366  F: 0.0009\n",
      "Epoch: 2800 - KL: 0.1805  Rec: 1.5870  CosSim: 0.0390  F: 0.0011\n",
      "Epoch: 2900 - KL: 0.1891  Rec: 1.4189  CosSim: 0.0389  F: 0.0011\n",
      "Epoch: 3000 - KL: 0.1913  Rec: 1.3860  CosSim: 0.0400  F: 0.0012\n",
      "epoch:[3000/10000]: loss:1.684534\n",
      "Epoch: 3100 - KL: 0.1785  Rec: 1.1528  CosSim: 0.0413  F: 0.0011\n",
      "Epoch: 3200 - KL: 0.1789  Rec: 1.5004  CosSim: 0.0384  F: 0.0009\n",
      "Epoch: 3300 - KL: 0.1776  Rec: 1.5654  CosSim: 0.0410  F: 0.0011\n",
      "Epoch: 3400 - KL: 0.1801  Rec: 1.3295  CosSim: 0.0372  F: 0.0009\n",
      "Finished Mapping!\n",
      "Setup: 291.4807599989872\n",
      "Get subset samples: 0.012344557163596472\n",
      "Run model: 0.019470652323948383\n",
      "KL Loss: 0.00035244525643801384\n",
      "Reconstruction Loss: 0.00029186368847750337\n",
      "Difference calculation: 0.001689026732907369\n",
      "Cosine Loss: 0.00015337694641289417\n",
      "F Loss: 0.00016300182258758926\n",
      "Step: 0.05072705081426937\n",
      "Output: 0.5756363770051394\n",
      "Total: 292.14158835074096\n",
      "---------------------------------\n",
      "JAMIE Done!\n",
      "Distance: 2200.251519626996\n",
      "Distance Memory: Stored 1351648984 - Peak 31920906273\n",
      "Correspondence: 45008.53014987399\n",
      "Correspondence Memory: Stored 337973916 - Peak 1351302201\n",
      "Mapping: 5348.666590211011\n",
      "Mapping Memory: Stored 642955651 - Peak 18380620735\n",
      "Total: 52557.44825971199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jm = JAMIE(**kwargs, debug=True, enable_memory_logging=True)\n",
    "jm_data = jm.fit_transform(dataset=dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmacom",
   "language": "python",
   "name": "nmacom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
